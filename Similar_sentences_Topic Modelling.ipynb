{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875644de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from sentence_transformers import util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2584025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e06266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7046393   0.21647064  0.23562156 ... -0.81505114 -0.3474665\n",
      "   0.6278896 ]\n",
      " [ 0.05422518  0.892096    0.14136267 ...  0.6420069   0.23304999\n",
      "   0.75140697]]\n"
     ]
    }
   ],
   "source": [
    "def load_bert(bert_path):\n",
    "    if bert_path:\n",
    "        embed = SentenceTransformer(bert_path, device=device)\n",
    "\n",
    "    else:\n",
    "        embed = None\n",
    "    return embed\n",
    "#model = load_bert(\"/Users/mac/Desktop/TeamSolve/models/stsb-roberta-base-v2\")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/stsb-roberta-base-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n",
    "\n",
    "def get_embedding(txt, model, model_type = \"BERT\"):\n",
    "    embedding = []\n",
    "    try_counter = 0\n",
    "    if model:\n",
    "            try:\n",
    "                if type(txt) is str or type(txt) is not list:\n",
    "                    txt = [txt]\n",
    "                if(model_type == \"USE\"):\n",
    "                    embedding = (np.asarray((model(txt))[0]))\n",
    "    #                embedding = (np.asarray(embedding))\n",
    "                \n",
    "                elif(model_type == \"BERT\"):\n",
    "                    embedding = (model.encode(txt))[0]\n",
    "\n",
    "                elif(model_type == \"BERT_MULTILINGUAL\"):\n",
    "                    embedding = (model.encode(txt))[0]                  \n",
    "                embedding = (embedding/np.linalg.norm(embedding)).tolist()\n",
    "                \n",
    "            except Exception as error:\n",
    "                print(\"error in getting embedding, retry count = \" + str(try_counter))\n",
    "#                raise Exception('error in embedding classifier')\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def get_cosine_similarity(matrix, vector, model_type=\"BERT\"):\n",
    "    neighbors = 0\n",
    "    try:\n",
    "        if model_type==\"TFIDF\":\n",
    "            neighbors = linear_kernel(matrix, vector).flatten()\n",
    "        else:\n",
    "            vector = np.asarray(vector)\n",
    "            matrix = np.asarray(matrix)\n",
    "            if matrix.shape == (0,): return [0]\n",
    "            neighbors = np.asarray(util.pytorch_cos_sim(matrix, vector))\n",
    "    except Exception as error:\n",
    "        raise Exception('error in embedding classifier-similarity function')\n",
    "    return neighbors\n",
    "\n",
    "def get_embeddings(queries, model=None, model_type = \"BERT\"):\n",
    "    #find embedding for a list of queries. Queries is expected to list of list\n",
    "    try:\n",
    "        if model_type==\"TFIDF\":\n",
    "            embeddings = TfidfVectorizer().fit_transform(queries)\n",
    "        else:\n",
    "            embeddings = []\n",
    "            for query in queries:\n",
    "                embeddings.append(get_embedding(query, model, model_type))\n",
    "\n",
    "    except Exception as error: \n",
    "        raise Exception('error in embedding classifier')\n",
    "        \n",
    "    return embeddings\n",
    "def get_similar_sentences(text):\n",
    "    sentences = text.split('.')\n",
    "    index_occupied = []\n",
    "    sentence_groups = []\n",
    "    embeddings = get_embeddings(sentences, model, model_type=\"BERT\")\n",
    "    all_scores = list()\n",
    "    for sent_id in range(len(sentences)):\n",
    "        similar_g = []\n",
    "        scores = get_cosine_similarity(embeddings, embeddings[sent_id], model_type=\"BERT\")\n",
    "        if sent_id in index_occupied:continue\n",
    "        similar_g.append(sentences[sent_id])\n",
    "        for n_sent in range(sent_id+1,len(sentences)):\n",
    "            score = scores[n_sent][0]\n",
    "            if score>=0.3:\n",
    "                similar_g.append(sentences[n_sent])\n",
    "                index_occupied.append(n_sent)\n",
    "            else:\n",
    "                break\n",
    "        sentence_groups.append(similar_g)\n",
    "\n",
    "        all_scores.append(scores)\n",
    "    return sentence_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f9deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = (get_similar_sentences(\"DMA 3 is part of the Kitchener network. The average DMA water demand is 15 CMH with max demand of 18 CMH at 8AM and min demand of 8 CMH at 3AM. Pumping station S1 supplies the water to the DMA. Flow meter FM3 is at the outlet of the pumping station and inlet of the DMA and measures the pump station outflow to the DMA. The DMA is isolated from the rest of the network by 2 closed valves: V11 and V12. In the DMA we have two pressure sensors P31 and P32. The average pressure in the DMA is 67 PSI. In the DMA we have 760 customers. Customer C31 typically experiences low pressure if there is a pipe burst in the DMA. You have access to data from pressure sensors P31, P32 and flow meter FM3 so whenever someone needs to know what the data is or set up an alarm, they can ask you to do that for them.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67819214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DMA 3 is part of the Kitchener network',\n",
       "  ' The average DMA water demand is 15 CMH with max demand of 18 CMH at 8AM and min demand of 8 CMH at 3AM',\n",
       "  ' Pumping station S1 supplies the water to the DMA',\n",
       "  ' Flow meter FM3 is at the outlet of the pumping station and inlet of the DMA and measures the pump station outflow to the DMA'],\n",
       " [' The DMA is isolated from the rest of the network by 2 closed valves: V11 and V12',\n",
       "  ' In the DMA we have two pressure sensors P31 and P32'],\n",
       " [' The average pressure in the DMA is 67 PSI',\n",
       "  ' In the DMA we have 760 customers',\n",
       "  ' Customer C31 typically experiences low pressure if there is a pipe burst in the DMA',\n",
       "  ' You have access to data from pressure sensors P31, P32 and flow meter FM3 so whenever someone needs to know what the data is or set up an alarm, they can ask you to do that for them'],\n",
       " ['']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5be28cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    " from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e23906da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating the model and tokenizer \n",
    "my_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fda974b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> average water demand is 15 CMH with max demand of 18 CMH at 8AM and min\n",
      "<pad> the pressure sensor is a sonic system that is able to operate a single\n",
      "<pad> average pressure in the DMA is 67 PSI In the DMA we have 760\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(sentences)-1):\n",
    "    Result = ''.join(sentences[i])\n",
    "    #summarize = [\"summarize\"]\n",
    "    #for i in range(s_len-1):\n",
    "    text = \"summarize:\" + Result\n",
    "    input_ids=tokenizer.encode(text, return_tensors='pt', max_length=512)\n",
    "    summary_ids = my_model.generate(input_ids)\n",
    "    summary_ids\n",
    "    t5_summary = tokenizer.decode(summary_ids[0])\n",
    "    print(t5_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebfa6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c7c9a79",
   "metadata": {},
   "source": [
    "End of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b850e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c8cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5a236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7af14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02b122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc392c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd924d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result =0\n",
    "for j in (0, len(sentences)-1):\n",
    "    for i in (0, len(sentences)-1):\n",
    "        Result = ''.join(sentences[i][j])\n",
    "        i=0\n",
    "        #summarize = [\"summarize\"]\n",
    "        for i in range(s_len-1):\n",
    "            text = \"summarize:\" + Result\n",
    "            input_ids=tokenizer.encode(text, return_tensors='pt', max_length=512)\n",
    "            summary_ids = my_model.generate(input_ids)\n",
    "            summary_ids\n",
    "            t5_summary = tokenizer.decode(summary_ids[0])\n",
    "            print(t5_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629c353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = ' '.join(sum(sentences, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966526df",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ebe52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fbff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "summarize = [\"summarize\"]\n",
    "for i in range(s_len-1):\n",
    "    text =  summarize + sentences[0]\n",
    "    input_ids=tokenizer.encode(text, return_tensors='pt', max_length=512)\n",
    "    summary_ids = my_model.generate(input_ids)\n",
    "    summary_ids\n",
    "    t5_summary = tokenizer.decode(summary_ids[0])\n",
    "    print(t5_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d406122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff9088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarizer = pipeline(\"summarization\",model=summarizer(\"faceboo/bart-large-xsum\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5943f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U nltk # To Upgrade NLTK to >3.5 for METEOR score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7022e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "\n",
    "# print('The nltk version is {}.'.format(nltk.__version__)) # Verify version >3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dca656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b9890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model=BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ad42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = 'Junk foods taste good that’s why it is mostly liked by everyone of any age group especially kids and school going children. They generally ask for the junk food daily because they have been trend so by their parents from the childhood. They never have been discussed by their parents about the harmful effects of junk foods over health. According to the research by scientists, it has been found that junk foods have negative effects on the health in many ways. They are generally fried food found in the market in the packets. They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers. Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life. It makes able a person to gain excessive weight which is called as obesity. Junk foods tastes good and looks good however do not fulfil the healthy calorie requirement of the body. Some of the foods like french fries, fried foods, pizza, burgers, candy, soft drinks, baked goods, ice cream, cookies, etc are the example of high-sugar and high-fat containing foods. It is found according to the Centres for Disease Control and Prevention that Kids and children eating junk food are more prone to the type-2 diabetes. In type-2 diabetes our body become unable to regulate blood sugar level. Risk of getting this disease is increasing as one become more obese or overweight. It increases the risk of kidney failure. Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers. It increases risk of cardiovascular diseases because it is rich in saturated fat, sodium and bad cholesterol. High sodium and bad cholesterol diet increases blood pressure and overloads the heart functioning. One who like junk food develop more risk to put on extra weight and become fatter and unhealthier. Junk foods contain high level carbohydrate which spike blood sugar level and make person more lethargic, sleepy and less active and alert. Reflexes and senses of the people eating this food become dull day by day thus they live more sedentary life. Junk foods are the source of constipation and other disease like diabetes, heart ailments, clogged arteries, heart attack, strokes, etc because of being poor in nutrition. Junk food is the easiest way to gain unhealthy weight. The amount of fats and sugar in the food makes you gain weight rapidly. However, this is not a healthy weight. It is more of fats and cholesterol which will have a harmful impact on your health. Junk food is also one of the main reasons for the increase in obesity nowadays.This food only looks and tastes good, other than that, it has no positive points. The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure. Above all, you can get various nutritional deficiencies when you don’t consume the essential nutrients, vitamins, minerals and more. You become prone to cardiovascular diseases due to the consumption of bad cholesterol and fat plus sodium. In other words, all this interferes with the functioning of your heart. Furthermore, junk food contains a higher level of carbohydrates. It will instantly spike your blood sugar levels. This will result in lethargy, inactiveness, and sleepiness. A person reflex becomes dull overtime and they lead an inactive life. To make things worse, junk food also clogs your arteries and increases the risk of a heart attack. Therefore, it must be avoided at the first instance to save your life from becoming ruined.The main problem with junk food is that people don’t realize its ill effects now. When the time comes, it is too late. Most importantly, the issue is that it does not impact you instantly. It works on your overtime; you will face the consequences sooner or later. Thus, it is better to stop now.You can avoid junk food by encouraging your children from an early age to eat green vegetables. Their taste buds must be developed as such that they find healthy food tasty. Moreover, try to mix things up. Do not serve the same green vegetable daily in the same style. Incorporate different types of healthy food in their diet following different recipes. This will help them to try foods at home rather than being attracted to junk food.In short, do not deprive them completely of it as that will not help. Children will find one way or the other to have it. Make sure you give them junk food in limited quantities and at healthy periods of time. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(original_text):\n",
    "    text = \"summarize:\" + original_text\n",
    "    input_ids=tokenizer.encode(text, return_tensors='pt', max_length=512)\n",
    "    summary_ids = my_model.generate(input_ids)\n",
    "    summary_ids\n",
    "    t5_summary = tokenizer.decode(summary_ids[0])\n",
    "    print(t5_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88af635",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.batch_encode_plus([original_text],return_tensors='pt')\n",
    "summary_ids = model.generate(inputs['input_ids'], early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(bart_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77779476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "\n",
    "# Instantiating the model and tokenizer \n",
    "my_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07e043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f879450",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the word \"summarize:\" to raw text\n",
    "text = \"summarize:\" + original_text\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb93938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the input text\n",
    "input_ids=tokenizer.encode(text, return_tensors='pt', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a44ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating summary ids\n",
    "summary_ids = my_model.generate(input_ids)\n",
    "summary_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed664f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding the tensor and printing the summary.\n",
    "t5_summary = tokenizer.decode(summary_ids[0])\n",
    "print(t5_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a9852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b4ce91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2547902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1bba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e63d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4521393d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
